{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amina/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D , MaxPooling2D , Flatten , Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier =Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Initializing the first layer\n",
    "classifier.add(Conv2D(32,(3,3),input_shape=(64,64,3),activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Dense(units= 128 , activation = 'relu'))\n",
    "classifier.add(Dense(units=1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam',loss='binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = ImageDataGenerator(rescale = 1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_data = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13862 images belonging to 2 classes.\n",
      "Found 213 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = train_data.flow_from_directory('images/train',target_size=(64,64),batch_size = 32,class_mode='binary')\n",
    "test = test_data.flow_from_directory('images/test',target_size=(64,64),batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "434/434 [==============================] - 77s 177ms/step - loss: 0.3282 - acc: 0.8695 - val_loss: 0.4288 - val_acc: 0.8122\n",
      "Epoch 2/10\n",
      "434/434 [==============================] - 93s 215ms/step - loss: 0.1960 - acc: 0.9258 - val_loss: 0.5758 - val_acc: 0.7653\n",
      "Epoch 3/10\n",
      "434/434 [==============================] - 96s 221ms/step - loss: 0.1540 - acc: 0.9423 - val_loss: 0.3406 - val_acc: 0.8732\n",
      "Epoch 4/10\n",
      "434/434 [==============================] - 83s 191ms/step - loss: 0.1404 - acc: 0.9465 - val_loss: 0.2569 - val_acc: 0.8920\n",
      "Epoch 5/10\n",
      "434/434 [==============================] - 95s 219ms/step - loss: 0.1380 - acc: 0.9505 - val_loss: 0.7477 - val_acc: 0.7418\n",
      "Epoch 6/10\n",
      "434/434 [==============================] - 90s 207ms/step - loss: 0.1359 - acc: 0.9505 - val_loss: 0.4158 - val_acc: 0.8545\n",
      "Epoch 7/10\n",
      "434/434 [==============================] - 89s 205ms/step - loss: 0.1265 - acc: 0.9533 - val_loss: 0.5168 - val_acc: 0.8310\n",
      "Epoch 8/10\n",
      "434/434 [==============================] - 85s 196ms/step - loss: 0.1201 - acc: 0.9561 - val_loss: 0.3378 - val_acc: 0.8545\n",
      "Epoch 9/10\n",
      "434/434 [==============================] - 104s 240ms/step - loss: 0.1040 - acc: 0.9627 - val_loss: 0.4020 - val_acc: 0.8498\n",
      "Epoch 10/10\n",
      "434/434 [==============================] - 95s 218ms/step - loss: 0.1027 - acc: 0.9636 - val_loss: 0.6588 - val_acc: 0.8075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11c9cde48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(train,steps_per_epoch=434,epochs = 10,validation_data=test,validation_steps=213)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagetest = image.load_img('images/23.jpg',target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAK7ElEQVR4nN2aSW/cRhCFi71wn4lG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\nQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x11C8D5DA0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagetest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### adding image as array\n",
    "imagetest = image.img_to_array(imagetest)\n",
    "## added as 3d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Modify to 1d array \n",
    "imagetest = np.expand_dims(imagetest,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0, 'pos': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-be0e55455cb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#result = [][]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m'neg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "#result = [][] \n",
    "if result[0][0]==1:\n",
    "    prediction = 'pos'\n",
    "else :\n",
    "    prediction =='neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = classifier.predict(imagetest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]]\n"
     ]
    }
   ],
   "source": [
    "prediction = classifier.predict(imagetest)\n",
    "print (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0, 'pos': 1}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
